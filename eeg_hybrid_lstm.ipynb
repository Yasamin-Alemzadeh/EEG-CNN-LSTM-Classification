{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, TimeDistributed, Conv2D, Flatten, Dense, Dropout, BatchNormalization, Activation, Reshape, GRU, LeakyReLU, Reshape, Permute, ConvLSTM2D, UpSampling2D, ZeroPadding2D, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Step 1: Define functions for data preprocessing ===\n",
    "def preprocess_eeg_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess EEG data from a .mat file.\n",
    "    - Normalize the data between 0 and 1.\n",
    "    - Extract segments and labels.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .mat file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed EEG data.\n",
    "        np.ndarray: Labels for the data (4-class classification).\n",
    "    \"\"\"\n",
    "    mat_data = scipy.io.loadmat(file_path)\n",
    "    eeg_data = mat_data['EEG_Seg']  # Assuming 'EEG_Seg' contains EEG data (62, 250, segments)\n",
    "    eeg_data = np.transpose(eeg_data, (2, 1, 0))  # Rearrange to (segments, 250, 62)\n",
    "\n",
    "    # Normalize EEG data to range [0, 1]\n",
    "    eeg_data = (eeg_data - np.min(eeg_data)) / (np.max(eeg_data) - np.min(eeg_data))\n",
    "\n",
    "    # Determine label based on file index (4-class labels)\n",
    "    file_index = int(os.path.basename(file_path).split('Data')[1].split('Segmented')[0])\n",
    "    if file_index <= 12:\n",
    "        label = 0  # Class 0: Healthy - Group 1\n",
    "    elif 12 < file_index <= 24:\n",
    "        label = 1  # Class 1: Impaired - Group 1\n",
    "    elif 24 < file_index <= 36:\n",
    "        label = 2  # Class 2: Healthy - Group 2\n",
    "    else:\n",
    "        label = 3  # Class 3: Impaired - Group 2\n",
    "\n",
    "    labels = np.full((eeg_data.shape[0],), label)  # Assign the label to all epochs\n",
    "    return eeg_data, labels\n",
    "\n",
    "# === Step 2: Process all files and prepare dataset ===\n",
    "def prepare_dataset(data_folder):\n",
    "    \"\"\"\n",
    "    Preprocess all EEG files in a folder and prepare the dataset.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Path to the folder containing .mat files.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed EEG data.\n",
    "        np.ndarray: Corresponding labels.\n",
    "    \"\"\"\n",
    "    eeg_data_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for file_name in os.listdir(data_folder):\n",
    "        if file_name.endswith('.mat'):\n",
    "            file_path = os.path.join(data_folder, file_name)\n",
    "            eeg_data, labels = preprocess_eeg_data(file_path)\n",
    "            eeg_data_list.append(eeg_data)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    eeg_data_combined = np.vstack(eeg_data_list)\n",
    "    labels_combined = np.concatenate(labels_list)\n",
    "    return eeg_data_combined, labels_combined\n",
    "\n",
    "# === Step 3: Hybrid LSTM Model ===\n",
    "def hybrid_LSTM(depth=2, conv_size=16, dense_size=512, input_dim=(250, 62, 1), dropoutRate=0.2, num_classes=4):\n",
    "    \"\"\"\n",
    "    Autoencoder model builder composes of CNNs and a LSTM\n",
    "    Args:\n",
    "        depth (int): number of CNN blocks, each has 3 CNN layers with BN and a dropout\n",
    "        conv_size (int): initial CNN filter size, doubled in each depth level\n",
    "        dense_size (int): size of latent vector and a number of filters of LSTM\n",
    "        input_dim (tuple): input dimension\n",
    "        dropoutRate (float): dropout rate used in all nodes\n",
    "        num_classes (int): number of classes for classification\n",
    "    Return:\n",
    "        keras model\n",
    "    \"\"\"\n",
    "    temp_filter = conv_size\n",
    "    model_input = Input(shape=input_dim, name='input')\n",
    "    X = model_input\n",
    "\n",
    "    # CNN Encoder\n",
    "    for i in range(depth):\n",
    "        for j in range(3):\n",
    "            if j == 0:\n",
    "                X = Conv2D(2 * temp_filter, (3, 3), padding='same', strides=(2, 2), name=f'encoder_{i}_{j}_conv2D')(X)\n",
    "            else:\n",
    "                X = Conv2D(temp_filter, (3, 3), padding='same', name=f'encoder_{i}_{j}_conv2D')(X)\n",
    "            X = BatchNormalization(name=f'encoder_{i}_{j}_BN')(X)\n",
    "            X = LeakyReLU(alpha=0.1, name=f'encoder_{i}_{j}_relu')(X)\n",
    "            X = Dropout(dropoutRate, name=f'encoder_{i}_{j}_drop')(X)\n",
    "        temp_filter *= 2\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = LSTM(dense_size, recurrent_dropout=dropoutRate, return_sequences=False)(Reshape((1, -1))(X))\n",
    "    latent = X\n",
    "\n",
    "    # Classification output\n",
    "    output = Dense(num_classes, activation='softmax', name='classifier')(latent)\n",
    "    return Model(inputs=model_input, outputs=output)\n",
    "\n",
    "# === Step 4: Main Execution ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify data folder\n",
    "    data_folder = \"./Data\"  # Replace with your data folder path\n",
    "\n",
    "    # Preprocess all files in the folder\n",
    "    print(\"Preprocessing EEG data...\")\n",
    "    eeg_data, labels = prepare_dataset(data_folder)\n",
    "    print(f\"Data preprocessing complete! Total samples: {eeg_data.shape[0]}\")\n",
    "\n",
    "    # Reshape data for CNN input\n",
    "    eeg_data = eeg_data[..., np.newaxis]  # Add channel dimension\n",
    "\n",
    "    # Convert labels to categorical (one-hot encoding)\n",
    "    labels = to_categorical(labels, num_classes=4)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(eeg_data, labels, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set size: {train_data.shape[0]}, Testing set size: {test_data.shape[0]}\")\n",
    "\n",
    "    # Build and compile the Hybrid LSTM model\n",
    "    model = hybrid_LSTM(input_dim=(250, 62, 1), num_classes=4)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Training the Hybrid LSTM model...\")\n",
    "    history = model.fit(train_data, train_labels, epochs=20, batch_size=32, validation_data=(test_data, test_labels))\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
